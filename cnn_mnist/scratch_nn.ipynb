{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (28, 28)\n",
    "EPOCH = 1000\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "# Import data\n",
    "data = pd.read_csv(r\"../digit-recognizer/train.csv\")\n",
    "data_test = pd.read_csv(r\"../digit-recognizer/test.csv\")    \n",
    "\n",
    "# Get labels and image array from data\n",
    "labels : np.ndarray = data.values[:, 0]\n",
    "images : np.ndarray = data.values[:, 1:].astype('uint8')\n",
    "\n",
    "images_test : np.ndarray = data_test.values.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference for backpropagation (from 3b1b neural network video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, input, hidden, output, lr):\n",
    "        # Initialize weight and bias\n",
    "        self.w_input = np.random.normal(size=(input, hidden))\n",
    "        self.b_input = np.zeros(hidden)\n",
    "        self.w_hidden = np.random.normal(size=(hidden, output))\n",
    "        self.b_hidden = np.zeros(output)\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.costs = []\n",
    "\n",
    "    def _sigmoid(self, x, derive=False):\n",
    "        if derive:\n",
    "            return self._sigmoid(x) * (1-self._sigmoid(x))\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _softmax(self, x : np.ndarray):\n",
    "        new_x : np.ndarray = np.zeros(len(x))\n",
    "        x = np.subtract(x, np.max(x))\n",
    "        # print(np.max(x))\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            new_x[i] = np.exp(x[i]) / np.sum(np.exp(x), axis=0)\n",
    "            # print(np.exp(x[i]))\n",
    "        # print(new_x)\n",
    "        return new_x \n",
    "\n",
    "    def plot(self):\n",
    "        plt.plot(self.costs, 'bo')\n",
    "        plt.xlabel(\"Data\")\n",
    "        plt.ylabel(\"Costs\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class Softmax(Model):\n",
    "    def __init__(self, input, hidden, output, lr):\n",
    "        super().__init__(input, hidden, output, lr)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = np.dot(x, self.w_input)\n",
    "        # x += self.b_input\n",
    "        # x = self._sigmoid(x)\n",
    "        x = np.dot(x, self.w_hidden)\n",
    "        x = np.clip(x, 1e-7, 1e4)\n",
    "        # x += self.b_hidden\n",
    "        x = self._softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def train(self, input: np.ndarray, pred: np.ndarray, label: np.ndarray, debug=False):\n",
    "        # ============================================\n",
    "        # Softmax with Cross Entropy Loss\n",
    "        \n",
    "        # cost = -sum(label * ln(pred)) = -ln(pred)\n",
    "        # label array only has one 1 value (the correct label), so technically, -ln(pred) is also correct\n",
    "        # pred = _softmax(out)\n",
    "        # out = w * input\n",
    "        # d_cost = -1 / (pred)\n",
    "        # d_pred = pred * (1 - pred) # From StatQuest\n",
    "        # d_cost * d_pred = pred[i] - 1\n",
    "        # self.w_input[j, i] -= step\n",
    "\n",
    "        d_cost = -1 / pred[np.argmax(label)] # d_cost\n",
    "        d_pred = np.zeros(len(pred))\n",
    "        out = np.dot(input, self.w_input)\n",
    "        # d_hidden = self.w_hidden\n",
    "\n",
    "        for i, p in enumerate(pred): # d_pred (derivative of _softmax)\n",
    "            # d__softmax/d_y1 = (e**y1 * (e**y2 + e**y3 + ...)) / (e**y1 + e**y2 + e**y3 + ...)**2\n",
    "            d_pred[i] = np.exp(p) * np.sum(np.exp(pred[pred != p])) / np.sum(np.exp(pred))**2\n",
    "                    \n",
    "        # print(input.shape, self.w_hidden.shape, d_pred.shape, d_cost)\n",
    "        # print(np.dot(self.w_hidden, d_pred).shape)\n",
    "        \n",
    "        self.w_input += (np.outer(input, np.dot(self.w_hidden, d_pred) * d_cost) * self.lr)\n",
    "        # self.b_hidden += d_pred * d_cost * self.lr\n",
    "        self.w_hidden += (np.outer(out, d_pred) * d_cost * self.lr)\n",
    "        # self.b_input += d_hidden * d_pred * d_cost * self.lr\n",
    "\n",
    "        self.costs.append(-np.log(pred[np.argmax(label)]))\n",
    "        \n",
    "        # Debug\n",
    "        if (debug):\n",
    "            print(\"Cost: \", -np.log(pred[np.argmax(label)]))\n",
    "            # print(\"Step: \", step)\n",
    "            # print(\"d_pred: \", d_pred)\n",
    "            # print(\"d_cost: \", d_cost)\n",
    "            \n",
    "        # ============================================\n",
    "\n",
    "\n",
    "\n",
    "class Sigmoid(Model):\n",
    "    def __init__(self, input, hidden, output, lr):\n",
    "        super().__init__(input, hidden, output, lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = np.dot(x, self.w_input)\n",
    "        # x += self.b_input\n",
    "        x = np.dot(x, self.w_hidden)\n",
    "        # x += self.b_hidden\n",
    "        x = self._sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def train(self, input: np.ndarray, pred: np.ndarray, label: np.ndarray, debug=False):\n",
    "        # ============================================\n",
    "        # # Sigmoid with MSELoss (Mean Squared Error)\n",
    "        # cost = 1/len(pred) * np.sum(pred-label)**2\n",
    "        # d_cost/d_pred = 2/len(pred) * (pred-label)\n",
    "        # d_cost = 10 (1 for each prediction?)\n",
    "        \n",
    "        # pred = _sigmoid(out) {a(L)}\n",
    "        # d_pred/d_out = self._sigmoid(out, derive=True)\n",
    "        # d_pred = 10 (1 for each output?)     \n",
    "        \n",
    "        # out = dot(dot(input, w_input), w_hidden)\n",
    "        # d_out/d_hidden = w_hidden (how much does hidden layer affects output, which depends on hidden layer's weight)\n",
    "        # d_out = hidden_size * output_size {(16, 10) matrix}\n",
    "\n",
    "        # hidden = dot(input, w_input)\n",
    "        # d_hidden/d_w_input = input (how much does weight affects hidden values, which depends on input)\n",
    "\n",
    "        # Gradient Descent\n",
    "        d_cost = 2/len(pred) * (pred-label) # (10, )\n",
    "        d_pred = self._sigmoid(np.dot(np.dot(input, self.w_input), self.w_hidden), derive=True) # (10, )\n",
    "        d_out = self.w_hidden # (16, 10)\n",
    "        d_hidden = input # (784, )\n",
    "\n",
    "        step = np.outer(d_hidden, np.dot(d_out, d_pred * d_cost))\n",
    "        # print(np.dot(input, self.w_input).shape)\n",
    "        self.w_hidden -= np.outer(np.dot(input, self.w_input), d_pred * d_cost)\n",
    "        self.w_input -= step\n",
    "        \n",
    "        self.costs.append(np.sum(pred-label)**2/len(pred))\n",
    "\n",
    "        # Debug\n",
    "        if (debug):\n",
    "            print(\"Cost: \", np.sum(pred-label)**2/len(pred))\n",
    "            # print(\"Step: \", step)\n",
    "            # print(\"d_pred: \", d_pred)\n",
    "            # print(\"d_cost: \", d_cost)\n",
    "            \n",
    "        # ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MODELS </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  0.09999980000010003\n",
      "Data 2000: Wrong = 1755, Accuracy: 12.206103051525758%\n",
      "Cost:  0.09999980000010003\n",
      "Data 4000: Wrong = 3386, Accuracy: 15.328832208052006%\n",
      "Cost:  0.09999980000010003\n",
      "Data 6000: Wrong = 5081, Accuracy: 15.302550425070848%\n",
      "Cost:  0.09999980000010003\n",
      "Data 8000: Wrong = 6716, Accuracy: 16.03950493811726%\n",
      "Cost:  0.09999980000010002\n",
      "Data 10000: Wrong = 8335, Accuracy: 16.641664166416632%\n",
      "Cost:  0.09999980000010003\n",
      "Data 12000: Wrong = 9925, Accuracy: 17.28477373114427%\n",
      "Cost:  0.09999980000010002\n",
      "Data 14000: Wrong = 11547, Accuracy: 17.51553682405887%\n",
      "Cost:  0.09999980000010003\n",
      "Data 16000: Wrong = 13171, Accuracy: 17.67610475654729%\n",
      "Cost:  2.3029673352947735e-13\n",
      "Data 18000: Wrong = 14778, Accuracy: 17.89543863547975%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAS GAMING\\AppData\\Local\\Temp\\ipykernel_19244\\3590800197.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:  0.09999980000010003\n",
      "Data 20000: Wrong = 16354, Accuracy: 18.225911295564785%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 22000: Wrong = 17967, Accuracy: 18.328105822991958%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 24000: Wrong = 19561, Accuracy: 18.492437184882704%\n",
      "Cost:  0.09999980000010003\n",
      "Data 26000: Wrong = 21176, Accuracy: 18.550713488980335%\n",
      "Cost:  0.09999980000010003\n",
      "Data 28000: Wrong = 22796, Accuracy: 18.582806528804596%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 30000: Wrong = 24381, Accuracy: 18.72729090969699%\n",
      "Cost:  0.09999980000010003\n",
      "Data 32000: Wrong = 26013, Accuracy: 18.70683458858089%\n",
      "Cost:  0.09999980000010002\n",
      "Data 34000: Wrong = 27621, Accuracy: 18.75937527574341%\n",
      "Cost:  0.09999980000010003\n",
      "Data 36000: Wrong = 29217, Accuracy: 18.839412205894618%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 38000: Wrong = 30809, Accuracy: 18.92155056712018%\n",
      "Cost:  0.09999980000010003\n",
      "Data 40000: Wrong = 32375, Accuracy: 19.060476511912796%\n",
      "Cost:  0.09999980000010002\n",
      "Data 42000: Wrong = 33961, Accuracy: 19.138550917878987%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 --> Wrong: 33961, Accuracy: 19.140476190476193%\n",
      "\n",
      "Cost:  0.09999980000010003\n",
      "Data 2000: Wrong = 1619, Accuracy: 19.009504752376188%\n",
      "Cost:  0.09999980000010003\n",
      "Data 4000: Wrong = 3200, Accuracy: 19.97999499874969%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 6000: Wrong = 4821, Accuracy: 19.636606101016838%\n",
      "Cost:  0.09999980000010003\n",
      "Data 8000: Wrong = 6406, Accuracy: 19.914989373671716%\n",
      "Cost:  0.09999980000010002\n",
      "Data 10000: Wrong = 8032, Accuracy: 19.671967196719677%\n",
      "Cost:  0.09999980000010003\n",
      "Data 12000: Wrong = 9623, Accuracy: 19.80165013751146%\n",
      "Cost:  0.09999980000010002\n",
      "Data 14000: Wrong = 11220, Accuracy: 19.8514179584256%\n",
      "Cost:  0.09999980000010003\n",
      "Data 16000: Wrong = 12845, Accuracy: 19.713732108256764%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 18000: Wrong = 14456, Accuracy: 19.684426912606256%\n",
      "Cost:  0.09999980000010003\n",
      "Data 20000: Wrong = 16026, Accuracy: 19.86599329966498%\n",
      "Cost:  0.09999980000010003\n",
      "Data 22000: Wrong = 17645, Accuracy: 19.791808718578125%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 24000: Wrong = 19267, Accuracy: 19.71748822867619%\n",
      "Cost:  0.09999980000010003\n",
      "Data 26000: Wrong = 20884, Accuracy: 19.673833608984964%\n",
      "Cost:  0.09999980000010003\n",
      "Data 28000: Wrong = 22514, Accuracy: 19.589985356619877%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 30000: Wrong = 24101, Accuracy: 19.660655355178505%\n",
      "Cost:  0.09999980000010003\n",
      "Data 32000: Wrong = 25714, Accuracy: 19.641238788712144%\n",
      "Cost:  0.09999980000010002\n",
      "Data 34000: Wrong = 27304, Accuracy: 19.691755639871772%\n",
      "Cost:  0.09999980000010003\n",
      "Data 36000: Wrong = 28895, Accuracy: 19.733881496708236%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 38000: Wrong = 30478, Accuracy: 19.792626121740042%\n",
      "Cost:  0.09999980000010003\n",
      "Data 40000: Wrong = 32039, Accuracy: 19.90049751243781%\n",
      "Cost:  0.09999980000010002\n",
      "Data 42000: Wrong = 33635, Accuracy: 19.91475987523512%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 --> Wrong: 33635, Accuracy: 19.91666666666667%\n",
      "\n",
      "Cost:  0.09999980000010003\n",
      "Data 2000: Wrong = 1605, Accuracy: 19.709854927463738%\n",
      "Cost:  0.09999980000010003\n",
      "Data 4000: Wrong = 3177, Accuracy: 20.55513878469617%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 6000: Wrong = 4797, Accuracy: 20.036672778796472%\n",
      "Cost:  0.09999980000010003\n",
      "Data 8000: Wrong = 6375, Accuracy: 20.302537817227147%\n",
      "Cost:  0.09999980000010002\n",
      "Data 10000: Wrong = 7984, Accuracy: 20.152015201520157%\n",
      "Cost:  0.09999980000010003\n",
      "Data 12000: Wrong = 9587, Accuracy: 20.10167513959496%\n",
      "Cost:  0.09999980000010002\n",
      "Data 14000: Wrong = 11196, Accuracy: 20.02285877562683%\n",
      "Cost:  0.09999980000010003\n",
      "Data 16000: Wrong = 12803, Accuracy: 19.97624851553222%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 18000: Wrong = 14433, Accuracy: 19.812211789543866%\n",
      "Cost:  0.09999980000010003\n",
      "Data 20000: Wrong = 16017, Accuracy: 19.910995549777482%\n",
      "Cost:  0.09996882972975477\n",
      "Data 22000: Wrong = 17623, Accuracy: 19.89181326423929%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 24000: Wrong = 19233, Accuracy: 19.859160798366602%\n",
      "Cost:  0.09999980000010003\n",
      "Data 26000: Wrong = 20868, Accuracy: 19.735374437478356%\n",
      "Cost:  0.09999980000010003\n",
      "Data 28000: Wrong = 22475, Accuracy: 19.72927604557306%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 30000: Wrong = 24061, Accuracy: 19.793993133104436%\n",
      "Cost:  0.09999980000010003\n",
      "Data 32000: Wrong = 25677, Accuracy: 19.75686740210631%\n",
      "Cost:  0.09999980000010002\n",
      "Data 34000: Wrong = 27266, Accuracy: 19.80352363304803%\n",
      "Cost:  0.09999980000010003\n",
      "Data 36000: Wrong = 28855, Accuracy: 19.844995694324837%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 38000: Wrong = 30442, Accuracy: 19.887365456985705%\n",
      "Cost:  0.09999980000010003\n",
      "Data 40000: Wrong = 32006, Accuracy: 19.98299957498938%\n",
      "Cost:  0.09999980000010002\n",
      "Data 42000: Wrong = 33602, Accuracy: 19.9933331745994%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 --> Wrong: 33602, Accuracy: 19.995238095238093%\n",
      "\n",
      "Cost:  0.09999980000010003\n",
      "Data 2000: Wrong = 1606, Accuracy: 19.659829914957484%\n",
      "Cost:  0.09999980000010003\n",
      "Data 4000: Wrong = 3200, Accuracy: 19.97999499874969%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 6000: Wrong = 4812, Accuracy: 19.7866311051842%\n",
      "Cost:  0.09999980000010003\n",
      "Data 8000: Wrong = 6392, Accuracy: 20.090011251406423%\n",
      "Cost:  0.09999980000010002\n",
      "Data 10000: Wrong = 7999, Accuracy: 20.002000200019992%\n",
      "Cost:  0.09999980000010003\n",
      "Data 12000: Wrong = 9586, Accuracy: 20.11000916743062%\n",
      "Cost:  0.09999980000010002\n",
      "Data 14000: Wrong = 11184, Accuracy: 20.10857918422745%\n",
      "Cost:  0.09999980000010003\n",
      "Data 16000: Wrong = 12795, Accuracy: 20.026251640727537%\n",
      "Cost:  8.099999999999998e-14\n",
      "Data 18000: Wrong = 14412, Accuracy: 19.92888493805212%\n",
      "Cost:  0.09999980000010003\n",
      "Data 20000: Wrong = 15983, Accuracy: 20.08100405020251%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19244\\3850723581.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# print(pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19244\\3590800197.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input, pred, label, debug)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# Gradient Descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0md_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (10, )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0md_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (10, )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[0md_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_hidden\u001b[0m \u001b[1;31m# (16, 10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0md_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m \u001b[1;31m# (784, )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Softmax(IMAGE_SIZE[0]*IMAGE_SIZE[1], 16, 10, LEARNING_RATE)\n",
    "model = Sigmoid(IMAGE_SIZE[0]*IMAGE_SIZE[1], 16, 10, LEARNING_RATE)\n",
    "\n",
    "# print(np.array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]) * np.array([2, 2, 3, 3]))\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    wrong = 0\n",
    "    for j, d in enumerate(images):\n",
    "        # High input breaks the neural network\n",
    "        # Problem such as NaN, inf, etc, because e sucks\n",
    "        d = d / 255\n",
    "        \n",
    "        pred = model.forward(d)\n",
    "        \n",
    "        # 0 will also break log e, because e sucks\n",
    "        # Clip pred so the value only ranges around 1e-7 and 1\n",
    "        pred = np.clip(pred, 1e-7, 1)\n",
    "\n",
    "        if (np.argmax(pred) != labels[j]):\n",
    "            wrong += 1\n",
    "            \n",
    "        label = np.zeros(10)\n",
    "        label[labels[j]] = 1\n",
    "        model.train(d, pred, label)\n",
    "\n",
    "        # print(pred)\n",
    "\n",
    "        if ((j+1) % 2000 == 0):\n",
    "            model.train(d, pred, label, True)\n",
    "            print(f\"Data {j+1}: Wrong = {wrong}, Accuracy: {100-wrong/j*100}%\")\n",
    "        \n",
    "\n",
    "    model.plot()\n",
    "    print(f\"Epoch: {i+1} --> Wrong: {wrong}, Accuracy: {100-wrong / labels.size * 100}%\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: [0.9999999988122101, 1.0, 1.5044041813706802e-14, 0.9999387959504074, 0.5, 1.0, 0.9999805945150844]\n",
      "Epoch 200: [0.9999999988143895, 1.0, 1.5069369488093772e-14, 0.9999388889407173, 0.5, 1.0, 0.9999806006437013]\n",
      "Epoch 300: [0.9999999988165591, 1.0, 1.5094668690142537e-14, 0.9999389815083315, 0.5, 1.0, 0.9999806067669631]\n",
      "Epoch 400: [0.9999999988187191, 1.0, 1.5119939556685965e-14, 0.9999390736564425, 0.5, 1.0, 0.9999806128848749]\n",
      "Epoch 500: [0.9999999988208697, 1.0, 1.514518222347371e-14, 0.9999391653882094, 0.5, 1.0, 0.9999806189974424]\n",
      "Epoch 600: [0.9999999988230108, 1.0, 1.5170396825213027e-14, 0.9999392567067577, 0.5, 1.0, 0.9999806251046702]\n",
      "Epoch 700: [0.9999999988251427, 1.0, 1.519558349556534e-14, 0.9999393476151808, 0.5, 1.0, 0.9999806312065642]\n",
      "Epoch 800: [0.999999998827265, 1.0, 1.5220742367159915e-14, 0.9999394381165386, 0.5, 1.0, 0.9999806373031289]\n",
      "Epoch 900: [0.9999999988293782, 1.0, 1.524587357161404e-14, 0.9999395282138609, 0.5, 1.0, 0.9999806433943701]\n",
      "Epoch 1000: [0.999999998831482, 1.0, 1.5270977239501126e-14, 0.9999396179101444, 0.5, 1.0, 0.9999806494802927]\n",
      "Epoch 1100: [0.999999998833577, 1.0, 1.5296053500430575e-14, 0.9999397072083553, 0.5, 1.0, 0.9999806555609024]\n",
      "Epoch 1200: [0.9999999988356627, 1.0, 1.5321102483005218e-14, 0.9999397961114297, 0.5, 1.0, 0.9999806616362041]\n",
      "Epoch 1300: [0.9999999988377397, 1.0, 1.534612431484542e-14, 0.9999398846222727, 0.5, 1.0, 0.9999806677062035]\n",
      "Epoch 1400: [0.9999999988398076, 1.0, 1.5371119122606774e-14, 0.9999399727437602, 0.5, 1.0, 0.9999806737709056]\n",
      "Epoch 1500: [0.9999999988418666, 1.0, 1.539608703200122e-14, 0.9999400604787382, 0.5, 1.0, 0.999980679830316]\n",
      "Epoch 1600: [0.9999999988439168, 1.0, 1.5421028167766108e-14, 0.9999401478300237, 0.5, 1.0, 0.99998068588444]\n",
      "Epoch 1700: [0.9999999988459585, 1.0, 1.544594265370869e-14, 0.9999402348004058, 0.5, 1.0, 0.9999806919332828]\n",
      "Epoch 1800: [0.9999999988479913, 1.0, 1.5470830612716893e-14, 0.9999403213926444, 0.5, 1.0, 0.9999806979768497]\n",
      "Epoch 1900: [0.9999999988500154, 1.0, 1.5495692166742687e-14, 0.9999404076094716, 0.5, 1.0, 0.9999807040151468]\n",
      "Epoch 2000: [0.9999999988520312, 1.0, 1.5520527436841637e-14, 0.999940493453592, 0.5, 1.0, 0.9999807100481788]\n",
      "Epoch 2100: [0.9999999988540385, 1.0, 1.5545336543164157e-14, 0.9999405789276838, 0.5, 1.0, 0.9999807160759512]\n",
      "Epoch 2200: [0.9999999988560373, 1.0, 1.557011960495397e-14, 0.9999406640343971, 0.5, 1.0, 0.9999807220984699]\n",
      "Epoch 2300: [0.9999999988580277, 1.0, 1.5594876740580878e-14, 0.9999407487763563, 0.5, 1.0, 0.99998072811574]\n",
      "Epoch 2400: [0.9999999988600099, 1.0, 1.5619608067557775e-14, 0.9999408331561591, 0.5, 1.0, 0.999980734127767]\n",
      "Epoch 2500: [0.9999999988619837, 1.0, 1.5644313702517356e-14, 0.9999409171763781, 0.5, 1.0, 0.9999807401345565]\n",
      "Epoch 2600: [0.9999999988639494, 1.0, 1.566899376122859e-14, 0.9999410008395597, 0.5, 1.0, 0.999980746136114]\n",
      "Epoch 2700: [0.999999998865907, 1.0, 1.5693648358634482e-14, 0.9999410841482257, 0.5, 1.0, 0.9999807521324448]\n",
      "Epoch 2800: [0.9999999988678565, 1.0, 1.571827760881233e-14, 0.9999411671048722, 0.5, 1.0, 0.9999807581235545]\n",
      "Epoch 2900: [0.9999999988697978, 1.0, 1.5742881625028843e-14, 0.9999412497119718, 0.5, 1.0, 0.9999807641094486]\n",
      "Epoch 3000: [0.9999999988717314, 1.0, 1.5767460519715002e-14, 0.9999413319719719, 0.5, 1.0, 0.999980770090133]\n",
      "Epoch 3100: [0.999999998873657, 1.0, 1.579201440449687e-14, 0.9999414138872967, 0.5, 1.0, 0.9999807760656126]\n",
      "Epoch 3200: [0.9999999988755746, 1.0, 1.581654339019266e-14, 0.9999414954603465, 0.5, 1.0, 0.9999807820358935]\n",
      "Epoch 3300: [0.9999999988774844, 1.0, 1.5841047586828616e-14, 0.999941576693498, 0.5, 1.0, 0.9999807880009809]\n",
      "Epoch 3400: [0.9999999988793866, 1.0, 1.5865527103619717e-14, 0.9999416575891054, 0.5, 1.0, 0.9999807939608806]\n",
      "Epoch 3500: [0.9999999988812809, 1.0, 1.588998204901867e-14, 0.9999417381494995, 0.5, 1.0, 0.9999807999155982]\n",
      "Epoch 3600: [0.9999999988831678, 1.0, 1.5914412530693956e-14, 0.9999418183769895, 0.5, 1.0, 0.999980805865139]\n",
      "Epoch 3700: [0.999999998885047, 1.0, 1.5938818655545783e-14, 0.9999418982738612, 0.5, 1.0, 0.9999808118095088]\n",
      "Epoch 3800: [0.9999999988869186, 1.0, 1.5963200529725033e-14, 0.9999419778423798, 0.5, 1.0, 0.9999808177487134]\n",
      "Epoch 3900: [0.9999999988887827, 1.0, 1.598755825862291e-14, 0.9999420570847877, 0.5, 1.0, 0.999980823682758]\n",
      "Epoch 4000: [0.9999999988906394, 1.0, 1.6011891946883657e-14, 0.9999421360033066, 0.5, 1.0, 0.9999808296116485]\n",
      "Epoch 4100: [0.9999999988924886, 1.0, 1.6036201698404632e-14, 0.9999422146001368, 0.5, 1.0, 0.9999808355353905]\n",
      "Epoch 4200: [0.9999999988943304, 1.0, 1.60604876163791e-14, 0.9999422928774581, 0.5, 1.0, 0.9999808414539896]\n",
      "Epoch 4300: [0.9999999988961652, 1.0, 1.6084749803251832e-14, 0.9999423708374288, 0.5, 1.0, 0.9999808473674512]\n",
      "Epoch 4400: [0.9999999988979926, 1.0, 1.6108988360771272e-14, 0.9999424484821878, 0.5, 1.0, 0.9999808532757815]\n",
      "Epoch 4500: [0.9999999988998127, 1.0, 1.6133203389968277e-14, 0.9999425258138537, 0.5, 1.0, 0.9999808591789856]\n",
      "Epoch 4600: [0.9999999989016257, 1.0, 1.6157394991146222e-14, 0.9999426028345246, 0.5, 1.0, 0.9999808650770695]\n",
      "Epoch 4700: [0.9999999989034316, 1.0, 1.6181563263949126e-14, 0.9999426795462796, 0.5, 1.0, 0.9999808709700387]\n",
      "Epoch 4800: [0.9999999989052304, 1.0, 1.6205708307313527e-14, 0.9999427559511779, 0.5, 1.0, 0.9999808768578989]\n",
      "Epoch 4900: [0.9999999989070223, 1.0, 1.6229830219493223e-14, 0.9999428320512603, 0.5, 1.0, 0.9999808827406558]\n",
      "Epoch 5000: [0.9999999989088071, 1.0, 1.6253929098074734e-14, 0.9999429078485478, 0.5, 1.0, 0.9999808886183154]\n",
      "Epoch 5100: [0.999999998910585, 1.0, 1.6278005039957812e-14, 0.9999429833450431, 0.5, 1.0, 0.9999808944908827]\n",
      "Epoch 5200: [0.999999998912356, 1.0, 1.6302058141389104e-14, 0.9999430585427304, 0.5, 1.0, 0.999980900358364]\n",
      "Epoch 5300: [0.9999999989141202, 1.0, 1.6326088497952296e-14, 0.9999431334435754, 0.5, 1.0, 0.9999809062207646]\n",
      "Epoch 5400: [0.9999999989158774, 1.0, 1.6350096204593994e-14, 0.9999432080495264, 0.5, 1.0, 0.9999809120780906]\n",
      "Epoch 5500: [0.999999998917628, 1.0, 1.6374081355598772e-14, 0.9999432823625127, 0.5, 1.0, 0.9999809179303472]\n",
      "Epoch 5600: [0.999999998919372, 1.0, 1.639804404462124e-14, 0.9999433563844474, 0.5, 1.0, 0.9999809237775407]\n",
      "Epoch 5700: [0.9999999989211092, 1.0, 1.6421984364678494e-14, 0.9999434301172248, 0.5, 1.0, 0.9999809296196761]\n",
      "Epoch 5800: [0.9999999989228399, 1.0, 1.6445902408154415e-14, 0.9999435035627229, 0.5, 1.0, 0.9999809354567599]\n",
      "Epoch 5900: [0.999999998924564, 1.0, 1.6469798266819668e-14, 0.9999435767228021, 0.5, 1.0, 0.9999809412887974]\n",
      "Epoch 6000: [0.9999999989262816, 1.0, 1.6493672031826517e-14, 0.9999436495993065, 0.5, 1.0, 0.9999809471157942]\n",
      "Epoch 6100: [0.9999999989279924, 1.0, 1.6517523793719117e-14, 0.999943722194063, 0.5, 1.0, 0.9999809529377565]\n",
      "Epoch 6200: [0.999999998929697, 1.0, 1.6541353642437903e-14, 0.9999437945088826, 0.5, 1.0, 0.9999809587546895]\n",
      "Epoch 6300: [0.999999998931395, 1.0, 1.6565161667309985e-14, 0.9999438665455598, 0.5, 1.0, 0.9999809645665994]\n",
      "Epoch 6400: [0.9999999989330868, 1.0, 1.658894795709155e-14, 0.999943938305873, 0.5, 1.0, 0.9999809703734915]\n",
      "Epoch 6500: [0.9999999989347723, 1.0, 1.6612712599932444e-14, 0.9999440097915845, 0.5, 1.0, 0.9999809761753721]\n",
      "Epoch 6600: [0.9999999989364514, 1.0, 1.663645568340412e-14, 0.9999440810044414, 0.5, 1.0, 0.9999809819722463]\n",
      "Epoch 6700: [0.9999999989381243, 1.0, 1.666017729450343e-14, 0.9999441519461754, 0.5, 1.0, 0.9999809877641201]\n",
      "Epoch 6800: [0.9999999989397907, 1.0, 1.668387751965502e-14, 0.9999442226185017, 0.5, 1.0, 0.9999809935509996]\n",
      "Epoch 6900: [0.9999999989414512, 1.0, 1.670755644471419e-14, 0.9999442930231219, 0.5, 1.0, 0.9999809993328902]\n",
      "Epoch 7000: [0.9999999989431057, 1.0, 1.6731214154974856e-14, 0.9999443631617213, 0.5, 1.0, 0.9999810051097977]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19244\\3581306648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19244\\3590800197.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input, pred, label, debug)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# print(np.dot(input, self.w_input).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_hidden\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_input\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "testing = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 0],\n",
    "    [1, 0, 0],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "label = np.array(\n",
    "    [1, 1, 1, 1, 0, 1, 1]\n",
    ")\n",
    "\n",
    "model = Sigmoid(3, 1024, 1, LEARNING_RATE)\n",
    "for e in range(1000000):\n",
    "    results = []\n",
    "    for i, d in enumerate(testing):\n",
    "        res = float(model.forward(d))\n",
    "        \n",
    "        results.append(res)\n",
    "        model.train(d, np.array([res]), np.array(label[i]))\n",
    "    \n",
    "    if ((e+1) % 100 == 0):\n",
    "        print(f\"Epoch {e+1}: {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0a7ea84f13c5490ff16707edd4f345ddc4e5570f1b3225d67fb71a4ba2808c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
